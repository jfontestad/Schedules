FROM [ras_sas].[BI].[AuctionSales] as aucs
join [ras_sas].[BI].[AppraisalBookRegionAdjustmentsMKT] as reg
on aucs.M1AppraisalBookIssueId=reg.AppraisalBookIssueID and aucs.CategoryId=reg.CategoryID
join [ras_sas].[BI].[AppraisalBookRegionMappingMKT] map
on map.CountryCode=reg.CountryCode and map.Region=reg.Region and map.StateProvince=aucs.LocationState
and map.AppraisalBookIssueID=reg.AppraisalBookIssueID
where aucs.categoryId=2616
and reg.CategoryID=2616
and saleyear>=2019
and reg.[AppraisalBookPublishDate]>='2018-12-01'
AND aucs.[CountryCode]='USA'
and aucs.M1PrecedingFlv is not null
and DataSource='Taylor & Martin Inc.'
Union all
SELECT [InternetComparableId]
,[EquipmentTypeId]
,[SaleDate]
,[SalePrice]
,[SalePriceSF]
,[CurrentABCost]
,[M1SFUsage]
,[M1AppraisalBookIssueId]
,[M1AppraisalBookPublishDate]
,[M1PrecedingFlv]
,reg.RegionAdjustment
,[M1PrecedingFlv]*reg.RegionAdjustment as regionFLV
,[SalePriceSF]/([M1PrecedingFlv]*reg.RegionAdjustment) as SPm1flv
,[LocationState]
FROM [ras_sas].[BI].[AuctionSales] as aucs
join [ras_sas].[BI].[RegionAdjustmentsInProgressMKT] as reg
on  aucs.CategoryId=reg.CategoryID
join [ras_sas].[BI].[RegionMappingInProgressMKT] map
on map.CountryCode=reg.CountryCode and map.Region=reg.Region and map.StateProvince=aucs.LocationState
where aucs.categoryId=2616
and reg.CategoryID=2616
and salemonth='2020-02'
AND aucs.[CountryCode]='USA'
and aucs.M1PrecedingFlv is not null
and DataSource='Taylor & Martin Inc.'")
TractorPrice<- sqlQuery(channel,"
SET NOCOUNT ON
SELECT [InternetComparableId]
,[EquipmentTypeId]
,[SaleDate]
,[SalePrice]
,[SalePriceSF]
,[CurrentABCostUSNA]
,[M1SFUsage]
,[M1AppraisalBookIssueId]
,[M1AppraisalBookPublishDate]
,[M1PrecedingFlv]
,reg.RegionAdjustment
,[M1PrecedingFlv]*reg.RegionAdjustment as regionFLV
,[SalePriceSF]/([M1PrecedingFlv]*reg.RegionAdjustment) as SPm1flv
,[LocationState]
FROM [ras_sas].[BI].[AuctionSales] as aucs
join [ras_sas].[BI].[AppraisalBookRegionAdjustmentsMKT] as reg
on aucs.M1AppraisalBookIssueId=reg.AppraisalBookIssueID and aucs.CategoryId=reg.CategoryID
join [ras_sas].[BI].[AppraisalBookRegionMappingMKT] map
on map.CountryCode=reg.CountryCode and map.Region=reg.Region and map.StateProvince=aucs.LocationState
and map.AppraisalBookIssueID=reg.AppraisalBookIssueID
where aucs.categoryId=2616
and reg.CategoryID=2616
and saleyear>=2019
and reg.[AppraisalBookPublishDate]>='2018-12-01'
AND aucs.[CountryCode]='USA'
and aucs.M1PrecedingFlv is not null
and DataSource='Taylor & Martin Inc.'
Union all
SELECT [InternetComparableId]
,[EquipmentTypeId]
,[SaleDate]
,[SalePrice]
,[SalePriceSF]
,[CurrentABCostUSNA]
,[M1SFUsage]
,[M1AppraisalBookIssueId]
,[M1AppraisalBookPublishDate]
,[M1PrecedingFlv]
,reg.RegionAdjustment
,[M1PrecedingFlv]*reg.RegionAdjustment as regionFLV
,[SalePriceSF]/([M1PrecedingFlv]*reg.RegionAdjustment) as SPm1flv
,[LocationState]
FROM [ras_sas].[BI].[AuctionSales] as aucs
join [ras_sas].[BI].[RegionAdjustmentsInProgressMKT] as reg
on  aucs.CategoryId=reg.CategoryID
join [ras_sas].[BI].[RegionMappingInProgressMKT] map
on map.CountryCode=reg.CountryCode and map.Region=reg.Region and map.StateProvince=aucs.LocationState
where aucs.categoryId=2616
and reg.CategoryID=2616
and salemonth='2020-02'
AND aucs.[CountryCode]='USA'
and aucs.M1PrecedingFlv is not null
and DataSource='Taylor & Martin Inc.'")
join_data<-merge(config_file,TractorPrice,by='InternetComparableId') %>%
select(InternetComparableId,Category, Subcategory ,Make, Model,Year,Sleeper,HPAdjusted ,Transmission,Axles,AuctionDate,City,
DimTransmission,	DimHorsepower,	DimSleeper,SalePrice.y, SalePriceSF, CurrentABCost.y, M1AppraisalBookPublishDate,
M1PrecedingFlv, RegionAdjustment, regionFLV,   SPm1flv, LocationState) %>%
mutate(exclude = ifelse(SPm1flv<=2 & SPm1flv>-.1 & Year>=2000,'OK','Exclude'))
join_data<-merge(config_file,TractorPrice,by='InternetComparableId') %>%
select(InternetComparableId,Category, Subcategory ,Make, Model,Year,Sleeper,HPAdjusted ,Transmission,Axles,AuctionDate,City,
DimTransmission,	DimHorsepower,	DimSleeper,SalePrice.y, SalePriceSF, CurrentABCostUSNA, M1AppraisalBookPublishDate,
M1PrecedingFlv, RegionAdjustment, regionFLV,   SPm1flv, LocationState) %>%
mutate(exclude = ifelse(SPm1flv<=2 & SPm1flv>-.1 & Year>=2000,'OK','Exclude'))
#write.csv(join_data,'joindata.csv')
join_data %>% group_by(Make) %>% summarise(n=n())
join_data<-merge(config_file,TractorPrice,by='InternetComparableId') %>%
select(InternetComparableId,Category, Subcategory ,Make, Model,Year,Sleeper,HPAdjusted ,Transmission,Axles,AuctionDate,City,
DimTransmission,	DimHorsepower,	DimSleeper,SalePrice.y, SalePriceSF, CurrentABCostUSNA, M1AppraisalBookPublishDate,
M1PrecedingFlv, RegionAdjustment, regionFLV,   SPm1flv, LocationState) %>%
mutate(exclude = ifelse(SPm1flv<=2 & SPm1flv>-.1 & Year>=2000,'OK','Exclude')) %>%
filter(SubcategoryName =='TA Truck Tractors')
join_data<-merge(config_file,TractorPrice,by='InternetComparableId') %>%
select(InternetComparableId,Category, Subcategory ,Make, Model,Year,Sleeper,HPAdjusted ,Transmission,Axles,AuctionDate,City,
DimTransmission,	DimHorsepower,	DimSleeper,SalePrice.y, SalePriceSF, CurrentABCostUSNA, M1AppraisalBookPublishDate,
M1PrecedingFlv, RegionAdjustment, regionFLV,   SPm1flv, LocationState) %>%
mutate(exclude = ifelse(SPm1flv<=2 & SPm1flv>-.1 & Year>=2000,'OK','Exclude')) %>%
filter(Subcategory =='TA Truck Tractors')
################################## Transmission #################################
dim_trsm<-join_data %>% filter(DimTransmission %in% c('Automated Manual','Manual','Automatic')) %>%
select(-DimHorsepower,-DimSleeper)
boxplot(SPm1flv~DimTransmission,data = dim_trsm)
################################## Transmission #################################
dim_trsm<-join_data %>% filter(DimTransmission %in% c('Automated Manual','Manual','Automatic')) %>%
select(-DimHorsepower,-DimSleeper)
boxplot(SPm1flv~DimTransmission,data = dim_trsm)
join_data<-merge(config_file,TractorPrice,by='InternetComparableId') %>%
select(InternetComparableId,Category, Subcategory ,Make, Model,Year,Sleeper,HPAdjusted ,Transmission,Axles,AuctionDate,City,
DimTransmission,	DimHorsepower,	DimSleeper,SalePrice.y, SalePriceSF, CurrentABCostUSNA, M1AppraisalBookPublishDate,
M1PrecedingFlv, RegionAdjustment, regionFLV,   SPm1flv, LocationState) %>%
mutate(exclude = ifelse(SPm1flv<=2 & SPm1flv>-.1 & Year>=2000,'OK','Exclude')) %>%
filter(exclude=='OK') %>%
filter(Subcategory =='TA Truck Tractors')
#write.csv(join_data,'joindata.csv')
join_data %>% group_by(Make) %>% summarise(n=n())
################################## Transmission #################################
dim_trsm<-join_data %>% filter(DimTransmission %in% c('Automated Manual','Manual','Automatic')) %>%
select(-DimHorsepower,-DimSleeper)
boxplot(SPm1flv~DimTransmission,data = dim_trsm)
dim_trsm %>% group_by(DimTransmission) %>% summarise(n=n())
transMake<-data.frame(dim_trsm %>% group_by(Make) %>% summarise(n=n()) %>% filter(n>100) %>% select(Make))
k=3
outtrans<-matrix(NA,dim(transMake)[1],k)
ntrans<-matrix(NA,dim(transMake)[1],k)
for (i in 1:dim(transMake)[1]){
subdata = dim_trsm %>% filter(Make==transMake[i,])
fit_trm<-lm(log(SPm1flv)~DimTransmission -1,data = subdata)
for (j in 1:k){
outtrans[i,j]<-exp(coef(fit_trm)[j])
}
}
## cat/subcat level
fit_trm<-lm(log(SPm1flv)~DimTransmission -1,data = dim_trsm)
exp(coef(fit_trm))
################################## Horse Power #################################
dim_hp<-join_data %>% filter(!is.na(DimHorsepower)) %>%
select(-DimTransmission,-DimSleeper)
boxplot(SPm1flv~DimHorsepower,data = dim_hp)
## cat/subcat level
fit_hp<-lm(log(SPm1flv)~DimHorsepower-1,data = dim_hp)
exp(coef(fit_hp))
## cat/subcat
fit_slep<-lm(log(SPm1flv)~DimSleeper -1,data = dim_slp)
exp(coef(fit_slep))
################################## Sleeper #################################
dim_slp<-join_data %>% filter(!is.na(DimSleeper)) %>%
select(-DimHorsepower,-DimTransmission)
## cat/subcat
fit_slep<-lm(log(SPm1flv)~DimSleeper -1,data = dim_slp)
exp(coef(fit_slep))
transMake<-data.frame(dim_trsm %>% group_by(Make) %>% summarise(n=n()) %>% filter(n>100) %>% select(Make))
k=3
outtrans<-matrix(NA,dim(transMake)[1],k)
ntrans<-matrix(NA,dim(transMake)[1],k)
for (i in 1:dim(transMake)[1]){
subdata = dim_trsm %>% filter(Make==transMake[i,])
fit_trm<-lm(log(SPm1flv)~DimTransmission -1,data = subdata)
for (j in 1:k){
outtrans[i,j]<-exp(coef(fit_trm)[j])
}
}
colnames(outtrans)<-c('Automated Manual','Automatic','Manual')
rownames(outtrans)<-as.list(transMake$Make)
#out<-data.frame(DimTransmission=c(exp(coef(fit_trm)[1]) ,exp(coef(fit_trm)[2]),exp(coef(fit_trm)[3])))
counts<-dim_trsm %>% group_by(Make,DimTransmission) %>% summarise(n=n())
spread(counts,DimTransmission,n)
outtrans
library(RODBC)
library(RODBCext)
library(lattice)
library(latticeExtra)
library(dplyr)
library(tidyr)
library(tibble)
library(lubridate)
library(readxl)
library(stringr)
# country
#CountryCode = 'GBR'
CountryCode = 'USA'
# db enviroment & connect
#DBserver = 'production'
DBserver = 'rasquery'
## read input excel file and create a plot for storing the plots
file_path = "C:/Users/vanessa.li/Documents/GitHub/Schedules/doc"
setwd(file_path)
excelfile = '20200211 SchedulesManagement.xlsx'
plotFolder = paste("Plots",Sys.Date())
dir.create(plotFolder)
## set directory of r scripts
scripts_path = "C:/Users/vanessa.li/Documents/GitHub/Schedules/script"
setwd(scripts_path)
runa<-parse('a.input&func.r')
eval(runa)
setwd(scripts_path)
runb<-parse('b.sqlQueries.r')
eval(runb)
channel<-odbcConnect(DBserver)
## run sql queries
if (CountryCode == 'USA'){
publishDate <- Sys.Date() - days(day(Sys.Date()))
uploadData <- sqlQuery(channel,US_dataload)
uploadListing <- sqlQuery(channel,Listing_dataload)
MakeAdjData <- sqlExecute(channel,MakeAdjust_dataload,CategoryId, fetch=T)
LastMonth_Sched <- sqlQuery(channel,LM_USA_load)
LastMonth_depr <- sqlQuery(channel,Last_depr_USAload)
AllClass <- sqlQuery(channel,AllClass)
ReportGrp <-sqlQuery(channel,ReportGrp)
} else{
publishDate <- Sys.Date() - days(day(Sys.Date())) - days(day(Sys.Date() - days(day(Sys.Date()))))
uploadData <- sqlQuery(channel,UK_dataload)
#listingData <- sqlQuery(channel,Listing_dataload)
#MakeAdjData <- sqlQuery(channel,MakeAdjust_dataload,,CategoryId, fetch=T)
LastMonth_Sched <- sqlQuery(channel,LM_UK_load)
LastMonth_depr <- sqlQuery(channel,Last_depr_UKload)
AllClass <- sqlQuery(channel,AllClass)
}
#publishDate = as.Date('2019-08-31')
thirdLastM<-publishDate - days(day(publishDate)) - days(day(publishDate - days(day(publishDate))))
setwd(scripts_path)
## Read the R script
runc<-parse('c.listings.r')
rund<-parse('d.datacleaning.r')
rune<-parse('e.buildmodel.r')
runf<-parse('f.adjustment.r')
rung<-parse('g.violationcheck.r')
runh<-parse('h. depreciation&monthlimit.r')
runi<-parse('i.makeschedules.r')
runj<-parse('j.upload&plots.r')
## read input excel file and create a plot for storing the plots
file_path = "C:/Users/vanessa.li/Documents/GitHub/Schedules/doc"
setwd(file_path)
excelfile = '20200211 SchedulesManagement.xlsx'
plotFolder = paste("Plots",Sys.Date())
dir.create(plotFolder)
## set directory of r scripts
scripts_path = "C:/Users/vanessa.li/Documents/GitHub/Schedules/script"
setwd(scripts_path)
runa<-parse('a.input&func.r')
eval(runa)
setwd(scripts_path)
runb<-parse('b.sqlQueries.r')
eval(runb)
channel<-odbcConnect(DBserver)
## run sql queries
if (CountryCode == 'USA'){
publishDate <- Sys.Date() - days(day(Sys.Date()))
uploadData <- sqlQuery(channel,US_dataload)
uploadListing <- sqlQuery(channel,Listing_dataload)
MakeAdjData <- sqlExecute(channel,MakeAdjust_dataload,CategoryId, fetch=T)
LastMonth_Sched <- sqlQuery(channel,LM_USA_load)
LastMonth_depr <- sqlQuery(channel,Last_depr_USAload)
AllClass <- sqlQuery(channel,AllClass)
ReportGrp <-sqlQuery(channel,ReportGrp)
} else{
publishDate <- Sys.Date() - days(day(Sys.Date())) - days(day(Sys.Date() - days(day(Sys.Date()))))
uploadData <- sqlQuery(channel,UK_dataload)
#listingData <- sqlQuery(channel,Listing_dataload)
#MakeAdjData <- sqlQuery(channel,MakeAdjust_dataload,,CategoryId, fetch=T)
LastMonth_Sched <- sqlQuery(channel,LM_UK_load)
LastMonth_depr <- sqlQuery(channel,Last_depr_UKload)
AllClass <- sqlQuery(channel,AllClass)
}
#publishDate = as.Date('2019-08-31')
thirdLastM<-publishDate - days(day(publishDate)) - days(day(publishDate - days(day(publishDate))))
setwd(scripts_path)
## Read the R script
runc<-parse('c.listings.r')
rund<-parse('d.datacleaning.r')
rune<-parse('e.buildmodel.r')
runf<-parse('f.adjustment.r')
rung<-parse('g.violationcheck.r')
runh<-parse('h. depreciation&monthlimit.r')
runi<-parse('i.makeschedules.r')
runj<-parse('j.upload&plots.r')
eval(runc)
eval(rund)
eval(runc)
eval(rund)
### This process starts from effective date 2019-02-28 and will end in 2020-09-30. ###
EOMList<-seq(as.Date('2019-03-01'),length=20,by='1 month') -1
str <-sort(c(0:9,0:9))
CatDtUse <-data.frame(EOMList,str)
indexUse<- CatDtUse[CatDtUse$EOMList==publishDate,]$str
###split join level
split.joinlevel<-function(input,dataload,brwtype){
select.var<-c('CompId',	'CategoryId',	'CategoryName',	'SubcategoryId',	'SubcategoryName',	'MakeId',	'MakeName',	'ModelId',	'ModelName',
'ModelYear',	'SaleDate',	'EffectiveDate',	'SalePrice',	'M1Value',	'SaleType',	'M1AppraisalBookPublishDate',	'SaleAB',
'SPvalue',	'CurrentABCost',	'Age',	'Flag',	'YearFlag',	'Schedule')
select.var.brw<-c('BorrowSchedule',	'BorrowType')
Catlevel<-input %>% filter(Level2 =='Category') %>% select(-SubcategoryId,-MakeId)
Subcatlevel<-input %>% filter(Level2 == "SubcatGroup") %>% select(-MakeId)
Makelevel<-input %>% filter(Level2 =='Make')
if(brwtype=='brw'){
CatData <- merge(dataload,Catlevel, by=c("CategoryId","Country")) %>%
mutate(str = str_sub(CompId,-1)) %>%
filter(MakeId !=31 | (MakeId ==31 & str<=indexUse)) %>%
select(c(select.var,select.var.brw))
SubcatData <- merge(dataload,Subcatlevel, by=c('CategoryId',"SubcategoryId","Country")) %>%
mutate(str = str_sub(CompId,-1)) %>%
filter(MakeId !=31 | (MakeId ==31 & str<=indexUse)) %>%
select(c(select.var,select.var.brw))
MakeData<-merge(dataload,Makelevel, by=c('CategoryId',"SubcategoryId","MakeId","Country")) %>% select(c(select.var,select.var.brw))
}
else{
CatData <- merge(dataload,Catlevel, by=c("CategoryId","Country")) %>%
mutate(str = str_sub(CompId,-1)) %>%
filter(MakeId !=31 | (MakeId ==31 & str<=indexUse)) %>%
select(select.var)
SubcatData <- merge(dataload,Subcatlevel, by=c('CategoryId',"SubcategoryId","Country")) %>%
mutate(str = str_sub(CompId,-1)) %>%
filter(MakeId !=31 | (MakeId ==31 & str<=indexUse)) %>%
select(select.var)
MakeData<-merge(dataload,Makelevel, by=c('CategoryId',"SubcategoryId","MakeId","Country")) %>% select(select.var)
}
return(rbind(CatData,SubcatData,MakeData))}
###################################################################################################################
###################################################################################################################
######################################## Make Data Merge & Clean ##################################################
###################################################################################################################
###################################################################################################################
if(CountryCode == 'USA'){
####### Prepare the candidate output list for Part 3 schedules ########
####### ClassId list = All - Out - OutR ########
Out_make <- anti_join(AllClass,comb_Out %>% select(ClassificationId),by='ClassificationId') %>%
select(ClassificationId,CategoryName,CategoryId,SubcategoryName,SubcategoryId,MakeName,MakeId)
######## Join MList with Out + OutR tab (SubcatGroup) to get the CS - Schedule map ##########
### Subset of Out +OutR tab
CatMakemap<-merge(Mlist %>% filter(ApplyToAllCSMs =='Y' & SubcategoryId =='NULL') %>% select(CategoryId),comb_Out %>% filter(Level2=='SubcatGroup'), by='CategoryId') %>%
filter(SubcategoryId !='NULL') %>%
select(Schedule,CategoryId,SubcategoryId)
SubcatMakemap <-merge(Mlist %>% filter(ApplyToAllCSMs =='Y' & SubcategoryId != 'NULL') %>% select(SubcategoryId),comb_Out %>% filter(Level2=='SubcatGroup'), by='SubcategoryId') %>%
select(Schedule,CategoryId,SubcategoryId)
joinmap_make <-merge(rbind(CatMakemap,SubcatMakemap),ReportGrp,by='CategoryId')
######## Prepare the output mapping table for all makes schedules ########
make_output<-merge(joinmap_make,Out_make,by=c('CategoryId','SubcategoryId')) %>% filter(!is.na(MakeId))
}
### Combine C, CS and CSM levels of data into one & exclude bad data
Datainput<-split.joinlevel(In,uploadData,'') %>%
filter(as.Date(EffectiveDate)<=publishDate & Flag =='inUse') %>%
mutate(CompId = factor(CompId)) %>%
group_by(Schedule,SaleType) %>%
filter(SPvalue <= mean(SPvalue) + stdInd*sd(SPvalue) & SPvalue>= mean(SPvalue) - stdInd*sd(SPvalue))
if(CountryCode =='USA'){
### Listing - Join in Category level
CatListing <- revised_listing %>%
### Used for Feb to Nov 2019: bring in caterpillar data
mutate(M1AppraisalBookPublishDate=as.factor(publishDate)) %>%
select(CompId,CategoryId, CategoryName, SubcategoryId,SubcategoryName,MakeId, MakeName, ModelId, ModelName, ModelYear, SaleDate,EffectiveDate, Country,SalePrice, M1Value
,SaleType,M1AppraisalBookPublishDate,SaleAB, SPvalue,CurrentABCost,Age,Flag,YearFlag,Schedule) %>%
filter(Flag == 'inUse') %>%
group_by(Schedule) %>%
filter(SPvalue <= mean(SPvalue) + stdInd*sd(SPvalue) & SPvalue>= mean(SPvalue) - stdInd*sd(SPvalue))
}
###### create a table auction data that not using for informing regression, this table only used for plot
aucBorrow_all<-split.joinlevel(InR,uploadData,'brw') %>%
filter(as.Date(EffectiveDate)<=publishDate & Flag =='inUse') %>%
mutate(CompId = factor(CompId)) %>%
group_by(Schedule,SaleType) %>%
filter(SPvalue <= mean(SPvalue) + stdInd*sd(SPvalue) & SPvalue>= mean(SPvalue) - stdInd*sd(SPvalue))
### Combine C, CS and CSM levels of data into one & exclude bad data
Datainput_Ret<-aucBorrow_all %>% filter(SaleType=='Retail')
###### create a table auction data that not using for informing regression, this table only used for plot
retBorrow_all<-split.joinlevel(InA,uploadData,'brw') %>%
filter(as.Date(EffectiveDate)<=publishDate & Flag =='inUse') %>%
mutate(CompId = factor(CompId)) %>%
group_by(Schedule,SaleType) %>%
filter(SPvalue <= ave(SPvalue) + stdInd*sd(SPvalue) & SPvalue>= ave(SPvalue) - stdInd*sd(SPvalue))
Datainput_Auc<-retBorrow_all %>% filter(SaleType=='Auction')
### Combine C, CS and CSM levels of data into one & exclude bad data
Datainput_BothBrw<-split.joinlevel(InB,uploadData,'brw') %>%
filter(as.Date(EffectiveDate)<=publishDate & Flag =='inUse') %>%
mutate(CompId = factor(CompId)) %>%
group_by(Schedule,SaleType) %>%
filter(SPvalue <= ave(SPvalue) + stdInd*sd(SPvalue) & SPvalue>= ave(SPvalue) - stdInd*sd(SPvalue))
### combine regular and auction borrow - regression use data
if (CountryCode == 'USA'){
Data_comb <-rbind(Datainput,Datainput_Ret,Datainput_Auc,CatListing)
} else{
Data_comb <-rbind(Datainput,Datainput_Ret,Datainput_Auc)
}
SaleDtAuc_cd<-subset(Data_comb,Data_comb$SaleType=="Auction") %>%
filter(ModelYear >= ifelse(CategoryId %in% ListingIds,dep_endyr, ext_botYr) & ModelYear <=topyear) %>%
distinct()
leveragelist<-list()
SchedRetBorw <-SchedR %>% filter(BorrowType=='AuctionBorrowRetail')
auc_regression <- rbind(SchedRetBorw %>% select(Schedule),Sched %>% select(Schedule)) %>% distinct()
nSched_Auc<-dim(auc_regression)[1]
for (j in 1:nSched_Auc){
groupData<-SaleDtAuc_cd %>% filter(Schedule==auc_regression[j,1])
fit<-lm(SaleAB ~ Age,data = groupData)
cooksd <- cooks.distance(fit)
influential <- as.numeric(names(cooksd)[(cooksd > 40*mean(cooksd, na.rm=T) | cooksd >1)])
leveragelist[[j]]<-groupData[influential,]
}
## save the list of ids that marked as leverage points
leverage.pts<-subset(do.call(rbind,leveragelist),Age<3)$CompId
## remove leverage points
#SaleDtAuc <-SaleDtAuc_cd %>% filter(!CompId %in% leverage.pts)
##update data_all
Data_clean <- Data_comb %>% filter(!(SaleType =='Auction' & CompId %in% leverage.pts))
## Use recent data
Data.count<-Data_clean %>%
group_by(SaleType,Schedule,ModelYear) %>%
arrange(desc(SaleDate)) %>%
mutate(rowNum=row_number())
Data.count3m <- Data.count %>%
filter(as.Date(EffectiveDate)>=thirdLastM & rowNum ==threshold_rec.calc) %>%
select(SaleType,Schedule,ModelYear)
Data_all <- rbind(data.frame(merge(Data.count,Data.count3m,by=c('SaleType','Schedule','ModelYear')) %>% filter(as.Date(EffectiveDate)>=thirdLastM))
,data.frame(anti_join(Data.count,Data.count3m,by=c('SaleType','Schedule','ModelYear')) %>% filter(rowNum<=25)))
### combine regular and borrow data for plots use only & exclude leverage points
if (CountryCode == 'USA'){
Data_all_plot <-rbind(Datainput,Datainput_BothBrw,aucBorrow_all,retBorrow_all,CatListing) %>%
filter(!(SaleType =='Auction' & CompId %in% leverage.pts))
} else{
Data_all_plot <-rbind(Datainput,Datainput_BothBrw,aucBorrow_all,retBorrow_all) %>%
filter(!(SaleType =='Auction' & CompId %in% leverage.pts))
}
###################################################################################################################
### Data use for regression that split to auc and ret
SaleDtAuc<-subset(Data_all,Data_all$SaleType=="Auction") %>%
filter(ModelYear >= ifelse(CategoryId %in% ListingIds,dep_endyr, ext_botYr) & ModelYear <=topyear)
SaleDtRet<-data.frame(subset(Data_all,Data_all$SaleType!="Auction") %>%
filter(ModelYear >= ifelse(CategoryId %in% ListingIds,dep_endyr, ext_botYr) & ModelYear <=topyear)) %>%
mutate(SaleType ='Retail')
###################################################################################################################
###################################################################################################################
######################################## Regression Model on Retail only ##########################################
###################################################################################################################
# model year List
modelYr<- data.frame(ext_botYr:topyear)
colnames(modelYr) <-'ModelYear'
# number of modelyears in regression
nMY<-dim(modelYr)[1]
###### Age used in regression model
# nice rounding model years
topAge<-year(publishDate)-topyear + (month(publishDate)-6)/12
# month treated model years
CurrentAge<-seq(topAge,by=1,length.out = 12)
################# Prepare the list for regression looping #########################################################
# Number of groups
SchedAucBorw <-SchedR %>% filter(BorrowType=='RetailBorrowAuction')
retail_regression <- rbind(SchedAucBorw %>% select(Schedule),Sched %>% select(Schedule)) %>% distinct()
nSched_Ret<-dim(retail_regression)[1]
######################### Declare the variables #########################################################
RetailOutput_R<-matrix(0,nSched_Ret,length(CurrentAge))
AgeName<-paste("Age",CurrentAge,sep="_")
alpha2<-rep(NA,nSched_Ret)
checklist_ret<-rep(NA, nSched_Ret)
coef_ret = matrix(0,nSched_Ret,3)
#################### 3.A loop to run regression by schedule and calcualte recoveries by month treated age
for (j in 1:nSched_Ret){
groupData<-SaleDtRet %>% filter(Schedule==retail_regression[j,1])
if(nrow(groupData)>0){
################## regression Model #########################
check <- tryCatch(nls(SaleAB ~ L/(1+exp(K*(-Age+scal)))+S,start=list(L=1.2,K=-0.5,S=.3),control = nls.control(maxiter = 1000,minFactor=2^-24),data = groupData),error = function(e) e)
checklist_ret[j]=any(class(check) == 'error')
if(any(class(check) == 'error') == F){
fit<-nls(SaleAB ~ L/(1+exp(K*(-Age+scal)))+S,start=list(L=1.2,K=-0.5,S=.3),control = nls.control(maxiter = 1000,minFactor=2^-24),data = groupData)
alpha <- coef(fit)
coef_ret [j,]<- alpha
################## schedules #########################
for (k in 1:length(CurrentAge)){
RetailOutput_R[j,k]<-alpha[1]/(1+exp(min(max(slopecap_low,alpha[2]),slopecap_up)*(-CurrentAge[k]+scal)))+alpha[3]
}
}
else {
fit<-nls(SaleAB ~ L/(1+exp(K*(-Age+scal))),start=list(L=1.2,K=-0.5),control = nls.control(maxiter = 1000,minFactor=2^-24),data=groupData)
alpha <- coef(fit)
coef_ret [j,]<- c(alpha,0)
for (k in 1:length(CurrentAge)){
RetailOutput_R[j,k] <- alpha[1]/(1+exp(min(max(slopecap_low,alpha[2]),slopecap_up)*(-CurrentAge[k]+scal)))
}
}
alpha2[j]=alpha[2]
rownames(RetailOutput_R)<-retail_regression[,1]
colnames(RetailOutput_R)<-AgeName
rownames(coef_ret)<-retail_regression[,1]
}
}
alpha2_ls = data.frame(retail_regression,alpha2)
export_ret_regression = data.frame(retail_regression,checklist_ret)
# trim the table - build first column
outputRetail_AucB<-rownames_to_column(as.data.frame(RetailOutput_R))
coef_ret_out<-rownames_to_column(as.data.frame(coef_ret))
#name the row and columns
colnames(outputRetail_AucB)<-c("Schedule",topyear:ext_botYr)
colnames(coef_ret_out)<-c("Schedule",'coef1','coef2','coef3')
View(coef_ret)
topyear
MakeAdjData <- sqlExecute(channel,MakeAdjust_dataload,CategoryId, fetch=T)
